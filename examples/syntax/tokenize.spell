#Spell: Tokenize
^ Intent: produce stable, cross-platform tokens to enable deterministic inference and caching

@Tokenizer
  : utf8 -> tokens
  $ require: fn tokenize
  $ forbid: network
  $ forbid: persistence
  $ forbid: locale_settings
  $ prove: deterministic -> test: det
  $ prove: locale_free -> test: locale
  $ prove: order_preserved -> test: order
  $ prove: valid_utf8 -> test: valid_utf8
  $ prove: non_empty_input -> test: non_empty
